---
title: "COMPSCIX 415.2 Homework 9/Final"
author: "Bryan Hee"
date: "April 4, 2018"
output:
  html_document:
    number_sections: no
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(modelr)
library(rpart)
library(partykit)
library(randomForest)
library(ROCR)
```

#Bootstrapping

###Question 1
```{r Load Data}
Titanic_R2 <- read.csv(file = "C:/Users/BryanHee/OneDrive - stok LLC/Intro to Data Science/HW Assignments/Assignment 9/train.csv")

Titanic_R2[,sapply(Titanic_R2, is.character)] <- lapply(Titanic_R2[,sapply(Titanic_R2, is.character)], as.factor)

Titanic_R2 <- transform(Titanic_R2, Survived = as.factor(Survived)) %>%
  glimpse()

#Titanic_R2 <- mutate(Titanic_R2, Survived = factor(case_when(Titanic_R2$Survived == 1 ~ 'Survived', Titanic_R2$Survived == 0 ~ "Died"), levels = c('Survived', 'Died'), ordered = FALSE))
#Titanic_R2 %>%
#      glimpse()

```

###Question 2
```{r bootstrap x 100}
titanic_boot <- modelr::bootstrap(data = Titanic_R2, n = 100)
is.tibble(titanic_boot)
titanic_boot
```

```{r Verify list resample 100}
titanic_boot$strap[[100]] %>%
  as.tibble() %>%
  glimpse()
```


###Question 3
```{r}
as.tibble(titanic_boot$strap[[20]]) %>% n_distinct()
as.tibble(titanic_boot$strap[[40]]) %>% n_distinct()
as.tibble(titanic_boot$strap[[100]]) %>% n_distinct()

##double checking the above code is correct
dummy <- c(20, 40, 100)
double_check <- rep(NA, 3)

for(i in 1:3) {
  as.tibble(titanic_boot$strap[[dummy[i]]]) -> holder
  length(unique(holder$PassengerId)) -> double_check[i]
  rm(holder)
}
double_check
```

###Questions 4 & 5
```{r Age Central Limit Theorem}
age_mean <- function(dataset) {
  data <- as.tibble(dataset) # convert input data set to a tibble
  mean_age <- mean(data$Age, na.rm = TRUE) # take the mean of Age, remove NAs
  return(mean_age) # return the mean value of Age from data
}


# loop through the 100 bootstrap samples and use the age_mean()
# function
all_means <- rep(NA, 100)

# start the loop
for(i in 1:100) {
  all_means[i] <- age_mean(titanic_boot$strap[[i]])
}

# take a look at some of the means you calculated from your samples
head(all_means)

# convert to a tibble so we can use if for plotting
all_means <- tibble(all_means = all_means)

ggplot(all_means) +
  geom_histogram(mapping = aes(x = all_means), binwidth = 0.1) +
  labs(y = "count", x = "average age", title = "bootstrapped average age")
```

```{r Alternative Way}
##Alternative way
age_means <- rep(NA, 100)
for(i in 1:100){
  as.tibble(titanic_boot$strap[[i]]) -> holder
  mean(holder$Age, na.rm = TRUE) -> age_means[i]
  rm(holder)
}

age_means <- as.tibble(age_means)

ggplot(data = age_means) +
  geom_histogram(mapping = aes(x = value), binwidth = 0.1) +
  labs(y = "count", x = "average age", title = "bootstrapped average age")
```

###Question 6 - FINISH!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\[SE = \frac{\sigma}{\sqrt{n}}\] where \(\sigma\) is the standard deviation of Age and \(n\) is the size of our sample.


```{r Standard Error}

```


#Random Forest

###Question 1
```{r Data Split}
set.seed(987)

model_data <- resample_partition(Titanic_R2, c(test = 0.3, train = 0.7))
train_set <- as.tibble(model_data$train)
test_set <- as.tibble(model_data$test)
```

###Question 2 - UPDATE ANSWER!!!!!!!!!!!!!!!
Compared to last week's 3-feature tree, this tree seems to fragment more (i.e. the tree isn't simply going from one branch to a smaller one in a linear fashion, but instead truly bisecting the data with each split then continuing to split again (it's a more balanced looking tree)). Also each split point is a unique feature.

```{r Decision Tree}
tree_2 <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data = train_set)
tree_2
plot(as.party(tree_2))
```

###Question 3
```{r Random Forest}
rf_mod <- randomForest(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, 
                         data = train_set, 
                         ntrees = 500, 
                         mtry = 4, 
                         na.action = na.roughfix)
rf_mod
```

###Question 4
As expected the random forest represents a better fitting model due to the higher AUC.

```{r Tree vs Forest}
rf_preds <- predict(rf_mod, newdata = test_set, type = 'prob')[,2]
tree_preds <- predict(tree_2, newdata = test_set)[,2]

pred_rf <- prediction(predictions = rf_preds, labels = test_set$Survived)
pred_tree <- prediction(predictions = tree_preds, labels = test_set$Survived)

auc_rf <- performance(prediction.obj = pred_rf, measure = "auc")
auc_tree <- performance(prediction.obj = pred_tree, measure = "auc")

# extract the AUC value
auc_rf@y.values[[1]]
auc_tree@y.values[[1]]
```


###Question 5 - ADD LEGEND!!!!!!!!!!
```{r}
# get the FPR and TPR for the random forest model
perf_rf <- performance(pred_rf, measure = 'tpr', x.measure = 'fpr')
perf_rf_tbl <- tibble(perf_rf@x.values[[1]], perf_rf@y.values[[1]])

# Change the names of the columns of the tibble
names(perf_rf_tbl) <- c('fpr', 'tpr')

# get the FPR and TPR for the simple tree model
perf_tree <- performance(pred_tree, measure = 'tpr', x.measure = 'fpr')
perf_tree_tbl <- tibble(perf_tree@x.values[[1]], perf_tree@y.values[[1]])

# Change the names of the columns of the tibble
names(perf_tree_tbl) <- c('fpr', 'tpr')

#Combine results into one tibble

perf_tree_tbl

rf_vs_tree <- bind_rows(perf_rf_tbl, perf_tree_tbl)

# Plotting function for plotting a nice ROC curve using ggplot
plot_roc <- function(perf_tbl) {
  p <- ggplot(data = perf_tbl, aes(x = fpr, y = tpr)) +
  geom_line(color = 'blue') +
  geom_abline(intercept = 0, slope = 1, lty = 3) +
  labs(x = 'False positive rate', y = 'True positive rate') +
  theme_bw()
  return(p)
}

plot_roc(rf_vs_tree)
plot_roc(perf_rf_tbl)


ggplot() +
  geom_line(data = perf_tree_tbl, aes(x = fpr, y = tpr), color = 'red') +
  geom_line(data = perf_rf_tbl, aes(x = fpr, y = tpr), color = 'blue') +
  geom_abline(intercept = 0, slope = 1, lty = 3) +
  labs(x = 'False positive rate', y = 'True positive rate') +
  theme_bw()


```

###Question 6 - FINISH!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Based on the ROC curves, the BLANK model performs better. This is because BLANK. 

If we attain a true positive rate of ~0.75, the approximate false positive rate for the random forest model is  0.155, whereas the false positive rate for the simple tree model is  0.34.